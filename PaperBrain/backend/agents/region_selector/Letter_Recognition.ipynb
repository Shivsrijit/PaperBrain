{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-10-28T05:39:26.528983Z",
     "iopub.status.busy": "2025-10-28T05:39:26.528722Z",
     "iopub.status.idle": "2025-10-28T05:39:27.287614Z",
     "shell.execute_reply": "2025-10-28T05:39:27.286788Z",
     "shell.execute_reply.started": "2025-10-28T05:39:26.528965Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning for images in: ../preprocessor/aligned_outputs\n",
      "Found 2 images to process.\n",
      "\n",
      "Loading blank reference image: ../preprocessor/question_paper_templates/1.jpg\n",
      "Blank image processed successfully.\n",
      "\n",
      "--- Starting batch processing ---\n",
      "\n",
      "Processing image: ../preprocessor/aligned_outputs/1 copy.jpg\n",
      "Found 7 answer regions:\n",
      "  Region 1: [x=1384, y=920, w=184, h=56]\n",
      "  Region 2: [x=1408, y=1108, w=138, h=82]\n",
      "  Region 3: [x=1403, y=1278, w=146, h=59]\n",
      "  Region 4: [x=1393, y=1420, w=151, h=49]\n",
      "  Region 5: [x=1392, y=1577, w=156, h=52]\n",
      "  Region 6: [x=1405, y=1935, w=115, h=28]\n",
      "  Region 7: [x=986, y=2091, w=165, h=57]\n",
      "Saved debug image to evaluation_results/1 copy_result.png\n",
      "Saved data for Agent 2 to agent1_output/1 copy_data.json\n",
      "\n",
      "Processing image: ../preprocessor/aligned_outputs/1-2 copy.jpg\n",
      "Found 7 answer regions:\n",
      "  Region 1: [x=1401, y=929, w=150, h=54]\n",
      "  Region 2: [x=1405, y=1121, w=138, h=53]\n",
      "  Region 3: [x=1414, y=1271, w=131, h=65]\n",
      "  Region 4: [x=1399, y=1416, w=135, h=55]\n",
      "  Region 5: [x=1396, y=1578, w=141, h=50]\n",
      "  Region 6: [x=1409, y=1933, w=115, h=27]\n",
      "  Region 7: [x=1009, y=2085, w=171, h=61]\n",
      "Saved debug image to evaluation_results/1-2 copy_result.png\n",
      "Saved data for Agent 2 to agent1_output/1-2 copy_data.json\n",
      "\n",
      "--- Batch processing complete. ---\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "import json     # <-- NEW\n",
    "import base64   # <-- NEW\n",
    "\n",
    "# --- 1. Setup Your Inputs ---\n",
    "BLANK_IMAGE_PATH = '../preprocessor/question_paper_templates/1.jpg'\n",
    "FILLED_IMAGE_FOLDER = '../preprocessor/aligned_outputs'\n",
    "\n",
    "# --- 2. Create Output Directories ---\n",
    "os.makedirs(\"evaluation_results\", exist_ok=True) # For debug images\n",
    "os.makedirs(\"agent1_output\", exist_ok=True)      # <-- NEW: For Agent 2's data\n",
    "\n",
    "# --- 3. Automatically Find All Image Paths ---\n",
    "print(f\"Scanning for images in: {FILLED_IMAGE_FOLDER}\")\n",
    "image_extensions = ('*.jpg', '*.jpeg', '*.png')\n",
    "FILLED_IMAGE_PATHS = []\n",
    "for ext in image_extensions:\n",
    "    FILLED_IMAGE_PATHS.extend(glob.glob(os.path.join(FILLED_IMAGE_FOLDER, ext)))\n",
    "\n",
    "if not FILLED_IMAGE_PATHS:\n",
    "    print(f\"FATAL ERROR: No images found in {FILLED_IMAGE_FOLDER}\")\n",
    "    exit()\n",
    "\n",
    "print(f\"Found {len(FILLED_IMAGE_PATHS)} images to process.\")\n",
    "\n",
    "\n",
    "# --- 4. Load and Pre-process BLANK Image (Once) ---\n",
    "print(f\"\\nLoading blank reference image: {BLANK_IMAGE_PATH}\")\n",
    "img_blank = cv2.imread(BLANK_IMAGE_PATH)\n",
    "\n",
    "if img_blank is None:\n",
    "    print(f\"FATAL ERROR: Could not read blank image at {BLANK_IMAGE_PATH}\")\n",
    "    exit()\n",
    "\n",
    "gray_blank = cv2.cvtColor(img_blank, cv2.COLOR_BGR2GRAY)\n",
    "h, w = gray_blank.shape\n",
    "gray_blank = cv2.GaussianBlur(gray_blank, (5,5), 0)\n",
    "print(\"Blank image processed successfully.\")\n",
    "\n",
    "\n",
    "# --- 5. Start Loop to Process Each Answer Sheet ---\n",
    "print(\"\\n--- Starting batch processing ---\")\n",
    "for image_path in FILLED_IMAGE_PATHS:\n",
    "    print(f\"\\nProcessing image: {image_path}\")\n",
    "    \n",
    "    # --- 5a. Load FILLED Image ---\n",
    "    img_filled = cv2.imread(image_path)\n",
    "    if img_filled is None:\n",
    "        print(f\"Skipping image, could not be loaded.\")\n",
    "        continue \n",
    "\n",
    "    # --- 5b. Pre-process FILLED Image ---\n",
    "    # Create the resized color image for Agent 2\n",
    "    img_filled_resized = cv2.resize(img_filled.copy(), (w, h))\n",
    "    \n",
    "    # Create the grayscale version for diff processing\n",
    "    gray_filled = cv2.cvtColor(img_filled_resized, cv2.COLOR_BGR2GRAY)\n",
    "    gray_filled = cv2.GaussianBlur(gray_filled, (5,5), 0)\n",
    "    \n",
    "    # Create the image for drawing boxes\n",
    "    img_with_boxes = img_filled_resized.copy()\n",
    "\n",
    "    # --- 5c. Find Differences ---\n",
    "    diff = cv2.absdiff(gray_blank, gray_filled)\n",
    "\n",
    "    # --- 5d. Threshold and Clean Up ---\n",
    "    _, thresh = cv2.threshold(diff, 30, 255, cv2.THRESH_BINARY)\n",
    "    kernel = np.ones((7,7), np.uint8)\n",
    "    clean = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel, iterations=2)\n",
    "    kernel_h = np.ones((5, 100), np.uint8)\n",
    "    merged_regions = cv2.dilate(clean, kernel_h, iterations=1)\n",
    "\n",
    "    # --- 5e. Find and Sort Regions ---\n",
    "    contours, _ = cv2.findContours(merged_regions, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    bounding_boxes = []\n",
    "    for c in contours:\n",
    "        x, y, w_c, h_c = cv2.boundingRect(c)\n",
    "        if (w_c * h_c) > 100:\n",
    "            # Convert numpy int32 to standard int for JSON\n",
    "            bounding_boxes.append((int(x), int(y), int(w_c), int(h_c))) \n",
    "\n",
    "    bounding_boxes.sort(key=lambda box: box[1])\n",
    "\n",
    "    # --- 5f. Output Coordinates and Visualize ---\n",
    "    print(f\"Found {len(bounding_boxes)} answer regions:\")\n",
    "    for j, (x, y, w_box, h_box) in enumerate(bounding_boxes):\n",
    "        print(f\"  Region {j+1}: [x={x}, y={y}, w={w_box}, h={h_box}]\")\n",
    "        cv2.rectangle(img_with_boxes, (x, y), (x+w_box, y+h_box), (0, 255, 0), 2)\n",
    "        cv2.putText(img_with_boxes, str(j+1), (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "\n",
    "    # --- 5g. Save Debug Image ---\n",
    "    base_name = os.path.basename(image_path)\n",
    "    file_name_only = os.path.splitext(base_name)[0]\n",
    "    output_filename = f\"evaluation_results/{file_name_only}_result.png\"\n",
    "    \n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(cv2.cvtColor(img_with_boxes, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(f\"Detected Regions for {base_name}\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig(output_filename)\n",
    "    plt.close()\n",
    "    print(f\"Saved debug image to {output_filename}\")\n",
    "\n",
    "    # --- 5h. NEW: Save Data for Agent 2 ---\n",
    "    # 1. Encode the resized color image to base64\n",
    "    _, buffer = cv2.imencode('.jpg', img_filled_resized)\n",
    "    image_base64 = base64.b64encode(buffer).decode('utf-8')\n",
    "    \n",
    "    # 2. Create the data packet\n",
    "    data_for_agent_2 = {\n",
    "        \"image_base64\": image_base64,\n",
    "        \"rois\": bounding_boxes\n",
    "    }\n",
    "    \n",
    "    # 3. Save as a JSON file\n",
    "    json_filename = f\"agent1_output/{file_name_only}_data.json\"\n",
    "    with open(json_filename, 'w') as f:\n",
    "        json.dump(data_for_agent_2, f)\n",
    "        \n",
    "    print(f\"Saved data for Agent 2 to {json_filename}\")\n",
    "\n",
    "print(\"\\n--- Batch processing complete. ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "tpuV5e8",
   "dataSources": [
    {
     "datasetId": 8588951,
     "sourceId": 13526907,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31155,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
