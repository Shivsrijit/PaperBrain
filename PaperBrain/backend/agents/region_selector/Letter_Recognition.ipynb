{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-10-28T05:39:26.528983Z",
     "iopub.status.busy": "2025-10-28T05:39:26.528722Z",
     "iopub.status.idle": "2025-10-28T05:39:27.287614Z",
     "shell.execute_reply": "2025-10-28T05:39:27.286788Z",
     "shell.execute_reply.started": "2025-10-28T05:39:26.528965Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning for images in: ../preprocessor/aligned_outputs\n",
      "Found 1 images to process.\n",
      "\n",
      "Loading blank reference image: ../preprocessor/question_paper_templates/2.jpg\n",
      "Blank image processed successfully.\n",
      "\n",
      "--- Starting batch processing ---\n",
      "\n",
      "Processing image: ../preprocessor/aligned_outputs/2 (1).jpg\n",
      "Found 16 answer regions:\n",
      "  Region 1: [x=1269, y=82, w=307, h=54]\n",
      "  Region 2: [x=524, y=234, w=204, h=63]\n",
      "  Region 3: [x=339, y=306, w=230, h=74]\n",
      "  Region 4: [x=582, y=406, w=231, h=46]\n",
      "  Region 5: [x=886, y=483, w=181, h=56]\n",
      "  Region 6: [x=540, y=575, w=194, h=40]\n",
      "  Region 7: [x=743, y=650, w=206, h=59]\n",
      "  Region 8: [x=1127, y=818, w=143, h=37]\n",
      "  Region 9: [x=1128, y=919, w=143, h=46]\n",
      "  Region 10: [x=1143, y=1057, w=137, h=45]\n",
      "  Region 11: [x=1133, y=1173, w=161, h=55]\n",
      "  Region 12: [x=1131, y=1305, w=146, h=44]\n",
      "  Region 13: [x=1122, y=1448, w=170, h=38]\n",
      "  Region 14: [x=1112, y=1737, w=319, h=68]\n",
      "  Region 15: [x=1118, y=1850, w=304, h=61]\n",
      "  Region 16: [x=514, y=2061, w=242, h=71]\n",
      "Saved result to evaluation_results/2 (1)_result.png\n",
      "\n",
      "--- Batch processing complete. ---\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# --- 1. Setup Your Inputs ---\n",
    "BLANK_IMAGE_PATH = '../preprocessor/question_paper_templates/2.jpg'\n",
    "FILLED_IMAGE_FOLDER = '../preprocessor/aligned_outputs'\n",
    "\n",
    "os.makedirs(\"evaluation_results\", exist_ok=True)\n",
    "\n",
    "# --- 2. Automatically Find All Image Paths ---\n",
    "print(f\"Scanning for images in: {FILLED_IMAGE_FOLDER}\")\n",
    "\n",
    "image_extensions = ('*.jpg', '*.jpeg', '*.png')\n",
    "FILLED_IMAGE_PATHS = []\n",
    "for ext in image_extensions:\n",
    "    FILLED_IMAGE_PATHS.extend(glob.glob(os.path.join(FILLED_IMAGE_FOLDER, ext)))\n",
    "\n",
    "if not FILLED_IMAGE_PATHS:\n",
    "    print(f\"FATAL ERROR: No images found in {FILLED_IMAGE_FOLDER}\")\n",
    "    exit()\n",
    "\n",
    "print(f\"Found {len(FILLED_IMAGE_PATHS)} images to process.\")\n",
    "\n",
    "# --- 3. Load and Pre-process BLANK Image (Once) ---\n",
    "print(f\"\\nLoading blank reference image: {BLANK_IMAGE_PATH}\")\n",
    "img_blank = cv2.imread(BLANK_IMAGE_PATH)\n",
    "\n",
    "if img_blank is None:\n",
    "    print(f\"FATAL ERROR: Could not read blank image at {BLANK_IMAGE_PATH}\")\n",
    "    exit()\n",
    "\n",
    "gray_blank = cv2.cvtColor(img_blank, cv2.COLOR_BGR2GRAY)\n",
    "h, w = gray_blank.shape\n",
    "gray_blank = cv2.GaussianBlur(gray_blank, (5,5), 0)\n",
    "print(\"Blank image processed successfully.\")\n",
    "\n",
    "# --- 4. Start Loop to Process Each Answer Sheet ---\n",
    "print(\"\\n--- Starting batch processing ---\")\n",
    "\n",
    "for image_path in FILLED_IMAGE_PATHS:\n",
    "    print(f\"\\nProcessing image: {image_path}\")\n",
    "    \n",
    "    # --- 4a. Load FILLED Image ---\n",
    "    img_filled = cv2.imread(image_path)\n",
    "    \n",
    "    if img_filled is None:\n",
    "        print(f\"Skipping image, could not be loaded.\")\n",
    "        continue \n",
    "\n",
    "    # --- 4b. Pre-process FILLED Image ---\n",
    "    gray_filled = cv2.cvtColor(img_filled, cv2.COLOR_BGR2GRAY)\n",
    "    gray_filled = cv2.resize(gray_filled, (w, h))\n",
    "    gray_filled = cv2.GaussianBlur(gray_filled, (5,5), 0)\n",
    "    \n",
    "    # ✅ RESIZE ONCE - Create img_with_boxes at the SAME size as processing\n",
    "    img_with_boxes = cv2.resize(img_filled.copy(), (w, h))\n",
    "\n",
    "    # --- 4c. Find Differences ---\n",
    "    diff = cv2.absdiff(gray_blank, gray_filled)\n",
    "\n",
    "    # --- 4d. Threshold and Clean Up ---\n",
    "    _, thresh = cv2.threshold(diff, 30, 255, cv2.THRESH_BINARY)\n",
    "    kernel = np.ones((7,7), np.uint8)\n",
    "    clean = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel, iterations=2)\n",
    "\n",
    "    # Merge words on the same line\n",
    "    kernel_h = np.ones((5, 100), np.uint8)\n",
    "    merged_regions = cv2.dilate(clean, kernel_h, iterations=1)\n",
    "\n",
    "    # --- 4e. Find and Sort Regions ---\n",
    "    contours, _ = cv2.findContours(merged_regions, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    bounding_boxes = []\n",
    "    for c in contours:\n",
    "        x, y, w_c, h_c = cv2.boundingRect(c)\n",
    "        if (w_c * h_c) > 100:\n",
    "            bounding_boxes.append((x, y, w_c, h_c))\n",
    "\n",
    "    bounding_boxes.sort(key=lambda box: box[1])\n",
    "\n",
    "    # --- 4f. Output Coordinates and Visualize ---\n",
    "    print(f\"Found {len(bounding_boxes)} answer regions:\")\n",
    "\n",
    "    for j, (x, y, w_box, h_box) in enumerate(bounding_boxes):\n",
    "        print(f\"  Region {j+1}: [x={x}, y={y}, w={w_box}, h={h_box}]\")\n",
    "        # ✅ Draw on the ALREADY RESIZED image - NO scaling needed\n",
    "        cv2.rectangle(img_with_boxes, (x, y), (x+w_box, y+h_box), (0, 255, 0), 2)\n",
    "        cv2.putText(img_with_boxes, str(j+1), (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "\n",
    "    # --- 4g. Save the Result ---\n",
    "    base_name = os.path.basename(image_path)\n",
    "    file_name_only = os.path.splitext(base_name)[0]\n",
    "    output_filename = f\"evaluation_results/{file_name_only}_result.png\"\n",
    "    \n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(cv2.cvtColor(img_with_boxes, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(f\"Detected Regions for {base_name}\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig(output_filename)\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"Saved result to {output_filename}\")\n",
    "\n",
    "print(\"\\n--- Batch processing complete. ---\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "tpuV5e8",
   "dataSources": [
    {
     "datasetId": 8588951,
     "sourceId": 13526907,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31155,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
