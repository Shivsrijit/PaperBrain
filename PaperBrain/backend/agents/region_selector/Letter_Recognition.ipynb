{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-10-28T05:39:26.528983Z",
     "iopub.status.busy": "2025-10-28T05:39:26.528722Z",
     "iopub.status.idle": "2025-10-28T05:39:27.287614Z",
     "shell.execute_reply": "2025-10-28T05:39:27.286788Z",
     "shell.execute_reply.started": "2025-10-28T05:39:26.528965Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning for images in: ../preprocessor/aligned_outputs\n",
      "Found 1 images to process.\n",
      "\n",
      "Loading blank reference image: ../preprocessor/question_paper_templates/2.jpg\n",
      "Blank image processed successfully.\n",
      "\n",
      "--- Starting batch processing ---\n",
      "\n",
      "Processing image: ../preprocessor/aligned_outputs/2_marked.jpeg\n",
      "Found 54 answer regions:\n",
      "  Region 1: [x=1240, y=55, w=447, h=27]\n",
      "  Region 2: [x=1135, y=82, w=549, h=72]\n",
      "  Region 3: [x=797, y=108, w=112, h=22]\n",
      "  Region 4: [x=51, y=181, w=466, h=37]\n",
      "  Region 5: [x=1357, y=182, w=213, h=29]\n",
      "  Region 6: [x=855, y=215, w=503, h=94]\n",
      "  Region 7: [x=876, y=220, w=208, h=6]\n",
      "  Region 8: [x=55, y=234, w=674, h=64]\n",
      "  Region 9: [x=55, y=306, w=641, h=75]\n",
      "  Region 10: [x=59, y=406, w=897, h=52]\n",
      "  Region 11: [x=55, y=484, w=1233, h=56]\n",
      "  Region 12: [x=55, y=575, w=807, h=45]\n",
      "  Region 13: [x=1065, y=580, w=111, h=5]\n",
      "  Region 14: [x=1045, y=595, w=145, h=7]\n",
      "  Region 15: [x=980, y=603, w=287, h=81]\n",
      "  Region 16: [x=57, y=650, w=1012, h=59]\n",
      "  Region 17: [x=1049, y=687, w=184, h=21]\n",
      "  Region 18: [x=51, y=746, w=458, h=37]\n",
      "  Region 19: [x=1357, y=748, w=214, h=30]\n",
      "  Region 20: [x=1117, y=789, w=182, h=89]\n",
      "  Region 21: [x=55, y=796, w=328, h=82]\n",
      "  Region 22: [x=554, y=828, w=339, h=29]\n",
      "  Region 23: [x=1117, y=907, w=182, h=89]\n",
      "  Region 24: [x=53, y=908, w=320, h=130]\n",
      "  Region 25: [x=554, y=947, w=277, h=30]\n",
      "  Region 26: [x=553, y=1040, w=746, h=89]\n",
      "  Region 27: [x=53, y=1057, w=321, h=94]\n",
      "  Region 28: [x=1117, y=1151, w=182, h=87]\n",
      "  Region 29: [x=53, y=1167, w=306, h=127]\n",
      "  Region 30: [x=554, y=1195, w=297, h=34]\n",
      "  Region 31: [x=1117, y=1287, w=182, h=89]\n",
      "  Region 32: [x=181, y=1318, w=184, h=73]\n",
      "  Region 33: [x=554, y=1328, w=303, h=31]\n",
      "  Region 34: [x=53, y=1330, w=142, h=29]\n",
      "  Region 35: [x=1117, y=1428, w=182, h=89]\n",
      "  Region 36: [x=50, y=1453, w=607, h=153]\n",
      "  Region 37: [x=553, y=1489, w=479, h=37]\n",
      "  Region 38: [x=1355, y=1570, w=140, h=30]\n",
      "  Region 39: [x=59, y=1648, w=1055, h=39]\n",
      "  Region 40: [x=54, y=1700, w=1028, h=114]\n",
      "  Region 41: [x=1033, y=1737, w=449, h=69]\n",
      "  Region 42: [x=53, y=1843, w=644, h=82]\n",
      "  Region 43: [x=1024, y=1850, w=451, h=75]\n",
      "  Region 44: [x=976, y=1901, w=105, h=8]\n",
      "  Region 45: [x=177, y=1926, w=506, h=14]\n",
      "  Region 46: [x=219, y=1942, w=103, h=9]\n",
      "  Region 47: [x=228, y=1954, w=100, h=5]\n",
      "  Region 48: [x=51, y=1973, w=1540, h=38]\n",
      "  Region 49: [x=55, y=2014, w=183, h=31]\n",
      "  Region 50: [x=461, y=2061, w=450, h=72]\n",
      "  Region 51: [x=53, y=2095, w=140, h=28]\n",
      "  Region 52: [x=354, y=2105, w=105, h=6]\n",
      "  Region 53: [x=57, y=2196, w=125, h=4]\n",
      "  Region 54: [x=213, y=2197, w=101, h=3]\n",
      "Saved result to evaluation_results/2_marked_result.png\n",
      "\n",
      "--- Batch processing complete. ---\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# --- 1. Setup Your Inputs ---\n",
    "BLANK_IMAGE_PATH = '../preprocessor/question_paper_templates/2.jpg'\n",
    "FILLED_IMAGE_FOLDER = '../preprocessor/aligned_outputs'\n",
    "\n",
    "os.makedirs(\"evaluation_results\", exist_ok=True)\n",
    "\n",
    "# --- 2. Automatically Find All Image Paths ---\n",
    "print(f\"Scanning for images in: {FILLED_IMAGE_FOLDER}\")\n",
    "\n",
    "image_extensions = ('*.jpg', '*.jpeg', '*.png')\n",
    "FILLED_IMAGE_PATHS = []\n",
    "for ext in image_extensions:\n",
    "    FILLED_IMAGE_PATHS.extend(glob.glob(os.path.join(FILLED_IMAGE_FOLDER, ext)))\n",
    "\n",
    "if not FILLED_IMAGE_PATHS:\n",
    "    print(f\"FATAL ERROR: No images found in {FILLED_IMAGE_FOLDER}\")\n",
    "    exit()\n",
    "\n",
    "print(f\"Found {len(FILLED_IMAGE_PATHS)} images to process.\")\n",
    "\n",
    "# --- 3. Load and Pre-process BLANK Image (Once) ---\n",
    "print(f\"\\nLoading blank reference image: {BLANK_IMAGE_PATH}\")\n",
    "img_blank = cv2.imread(BLANK_IMAGE_PATH)\n",
    "\n",
    "if img_blank is None:\n",
    "    print(f\"FATAL ERROR: Could not read blank image at {BLANK_IMAGE_PATH}\")\n",
    "    exit()\n",
    "\n",
    "gray_blank = cv2.cvtColor(img_blank, cv2.COLOR_BGR2GRAY)\n",
    "h, w = gray_blank.shape\n",
    "gray_blank = cv2.GaussianBlur(gray_blank, (5,5), 0)\n",
    "print(\"Blank image processed successfully.\")\n",
    "\n",
    "# --- 4. Start Loop to Process Each Answer Sheet ---\n",
    "print(\"\\n--- Starting batch processing ---\")\n",
    "\n",
    "for image_path in FILLED_IMAGE_PATHS:\n",
    "    print(f\"\\nProcessing image: {image_path}\")\n",
    "    \n",
    "    # --- 4a. Load FILLED Image ---\n",
    "    img_filled = cv2.imread(image_path)\n",
    "    \n",
    "    if img_filled is None:\n",
    "        print(f\"Skipping image, could not be loaded.\")\n",
    "        continue \n",
    "\n",
    "    # --- 4b. Pre-process FILLED Image ---\n",
    "    gray_filled = cv2.cvtColor(img_filled, cv2.COLOR_BGR2GRAY)\n",
    "    gray_filled = cv2.resize(gray_filled, (w, h))\n",
    "    gray_filled = cv2.GaussianBlur(gray_filled, (5,5), 0)\n",
    "    \n",
    "    # ✅ RESIZE ONCE - Create img_with_boxes at the SAME size as processing\n",
    "    img_with_boxes = cv2.resize(img_filled.copy(), (w, h))\n",
    "\n",
    "    # --- 4c. Find Differences ---\n",
    "    diff = cv2.absdiff(gray_blank, gray_filled)\n",
    "\n",
    "    # --- 4d. Threshold and Clean Up ---\n",
    "    _, thresh = cv2.threshold(diff, 30, 255, cv2.THRESH_BINARY)\n",
    "    kernel = np.ones((7,7), np.uint8)\n",
    "    clean = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel, iterations=2)\n",
    "\n",
    "    # Merge words on the same line\n",
    "    kernel_h = np.ones((5, 100), np.uint8)\n",
    "    merged_regions = cv2.dilate(clean, kernel_h, iterations=1)\n",
    "\n",
    "    # --- 4e. Find and Sort Regions ---\n",
    "    contours, _ = cv2.findContours(merged_regions, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    bounding_boxes = []\n",
    "    for c in contours:\n",
    "        x, y, w_c, h_c = cv2.boundingRect(c)\n",
    "        if (w_c * h_c) > 100:\n",
    "            bounding_boxes.append((x, y, w_c, h_c))\n",
    "\n",
    "    bounding_boxes.sort(key=lambda box: box[1])\n",
    "\n",
    "    # --- 4f. Output Coordinates and Visualize ---\n",
    "    print(f\"Found {len(bounding_boxes)} answer regions:\")\n",
    "\n",
    "    for j, (x, y, w_box, h_box) in enumerate(bounding_boxes):\n",
    "        print(f\"  Region {j+1}: [x={x}, y={y}, w={w_box}, h={h_box}]\")\n",
    "        # ✅ Draw on the ALREADY RESIZED image - NO scaling needed\n",
    "        cv2.rectangle(img_with_boxes, (x, y), (x+w_box, y+h_box), (0, 255, 0), 2)\n",
    "        cv2.putText(img_with_boxes, str(j+1), (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "\n",
    "    # --- 4g. Save the Result ---\n",
    "    base_name = os.path.basename(image_path)\n",
    "    file_name_only = os.path.splitext(base_name)[0]\n",
    "    output_filename = f\"evaluation_results/{file_name_only}_result.png\"\n",
    "    \n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(cv2.cvtColor(img_with_boxes, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(f\"Detected Regions for {base_name}\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig(output_filename)\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"Saved result to {output_filename}\")\n",
    "\n",
    "print(\"\\n--- Batch processing complete. ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "tpuV5e8",
   "dataSources": [
    {
     "datasetId": 8588951,
     "sourceId": 13526907,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31155,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
